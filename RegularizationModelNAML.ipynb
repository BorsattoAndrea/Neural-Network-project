{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RfXefwq0Sbsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glk5w_ZnPoq8",
        "outputId": "442a3de7-dd33-4145-a742-dc2397da0d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab = {'reggae':0,\n",
        "       'rock':1,\n",
        "       'country':2,\n",
        "       'disco':3,\n",
        "       'hiphop':4,\n",
        "       'classical':5,\n",
        "       'metal':6,\n",
        "       'blues':7,\n",
        "       'jazz':8,\n",
        "       'pop':9\n",
        "}      \n",
        "nBatch = 6\n",
        "batchDim = list()\n",
        "batchIndex = list()\n",
        "nsong = 100\n",
        "currentIdx = 0\n",
        "for i in range(nBatch):\n",
        "  nBatchSong =int(nsong / nBatch)\n",
        "  nBatch -= 1\n",
        "  batchDim.append(nBatchSong)\n",
        "  nsong -= nBatchSong\n",
        "\n",
        "  nextIdx = currentIdx + nBatchSong -1\n",
        "  idxs = (currentIdx, nextIdx)\n",
        "\n",
        "  currentIdx += nBatchSong\n",
        "  batchIndex.append(idxs)\n",
        "\n",
        "#example with nBatch = 6\n",
        "#batchDim = [17,17,17,17,16,16]\n",
        "#batchIndex =[(0,16),(17,33),(34,50),(51,67),(68,83),(84,99)]\n",
        "# 1) 17songs/genre indexes -> (0-16)\n",
        "# 2) 17songs/genre indexes -> (17-33)\n",
        "# 3) 17songs/genre indexes -> (34-50)\n",
        "# 4) 17songs/genre indexes -> (51-67)\n",
        "# 5) 16songs/genre indexes -> (68-83)\n",
        "# 6) 16songs/genre indexes -> (84-99)\n",
        "\n",
        "def loadBatch(index):\n",
        "  data = []\n",
        "  labels = []\n",
        "  dataset_path = \"/content/drive/MyDrive/genres\"\n",
        "\n",
        "  l = list()\n",
        "\n",
        "  segments_per_track = 21\n",
        "  overlapping = 0.75\n",
        "  track_length = 30 #seconds\n",
        "  sample_length = 5 #seconds\n",
        "\n",
        "  for i,(dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "    if dirpath is not dataset_path:\n",
        "      label = dirpath.split('/')[-1]\n",
        "      print(\"Loading %s\"%label)\n",
        "      for i,f in enumerate(filenames):\n",
        "        if i>=batchIndex[index][0] and i<=batchIndex[index][1]:\n",
        "          file_path = os.path.join(dirpath,f)\n",
        "          signal, sample_rate = librosa.load(file_path)\n",
        "          truncated = 0\n",
        "          if len(signal) < 661500: # if the track is less than 30 seconds i dont take the last segment\n",
        "            l.append(label)\n",
        "            truncated = 1\n",
        "          for s in range(segments_per_track - truncated ):\n",
        "            start_sample_index = int(s * (1-overlapping) * sample_length * sample_rate) #s = 0 -> 0, s = 1 -> int(27562.5) = 27562\n",
        "            end_sample_index = int(start_sample_index + sample_length * sample_rate-1) #s = 0 -> 27561 , s = 1 -> 55123\n",
        "            sample = signal[start_sample_index:end_sample_index+1]\n",
        "            data.append(sample)\n",
        "            labels.append(lab[label])\n",
        "  return np.array(data),np.array(labels)"
      ],
      "metadata": {
        "id": "SroutCK4dvoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchDim, batchIndex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt6NIeVtDE8l",
        "outputId": "b4ece4b0-0069-4ab2-86c4-987a868269c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([16, 16, 17, 17, 17, 17],\n",
              " [(0, 15), (16, 31), (32, 48), (49, 65), (66, 82), (83, 99)])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYZmvD78pbQj"
      },
      "outputs": [],
      "source": [
        "filter = [(2,128), (6,256), (1,512)]\n",
        "kernelS = 3\n",
        "poolS = 3\n",
        "stride = [3, 1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train=loadBatch(2)\n",
        "x_valid, y_valid=loadBatch(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45YxdDMld-ix",
        "outputId": "8f23004c-b04d-4f59-e1eb-c12ca989c7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading reggae\n",
            "Loading rock\n",
            "Loading country\n",
            "Loading disco\n",
            "Loading hiphop\n",
            "Loading classical\n",
            "Loading metal\n",
            "Loading blues\n",
            "Loading jazz\n",
            "Loading pop\n",
            "Loading reggae\n",
            "Loading rock\n",
            "Loading country\n",
            "Loading disco\n",
            "Loading hiphop\n",
            "Loading classical\n",
            "Loading metal\n",
            "Loading blues\n",
            "Loading jazz\n",
            "Loading pop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmRRBWQJGEnw",
        "outputId": "657c4e77-a8eb-4497-b49b-6197d03525d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3568, 110250)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def unison_shuffled_copies(a, b):\n",
        "    np.random.seed(int(time.time()))\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]"
      ],
      "metadata": {
        "id": "9DpS8Ai9DA-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
        "x_valid, y_valid = unison_shuffled_copies(x_valid, y_valid)"
      ],
      "metadata": {
        "id": "u0CGDEM5Gfwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "#check if everything correct\n",
        "sample_rate = 22050\n",
        "sf.write('prova.wav', x_train[100,:],sample_rate)\n",
        "\n",
        "print(Counter(y_train))\n",
        "y_train[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmwj0VMqO5NO",
        "outputId": "8fd56380-9ebe-4464-aa79-080995e73c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 357, 9: 357, 3: 357, 7: 357, 8: 357, 6: 357, 5: 357, 2: 357, 4: 356, 1: 356})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSn6WHsS8RgQ"
      },
      "outputs": [],
      "source": [
        "# Residual Layer\n",
        "def res1d(input, nFilters, kernelSize, stride):\n",
        "  y = keras.layers.Conv1D(filters = nFilters, kernel_size = kernelSize, strides = stride, padding = \"same\",kernel_regularizer=keras.regularizers.l1_l2(0,0.001))(input)  \n",
        "  y = keras.layers.BatchNormalization()(y)\n",
        "  y = keras.layers.LeakyReLU()(y)\n",
        "  y = keras.layers.Conv1D(filters = nFilters, kernel_size = kernelSize, strides = stride, padding = \"same\",kernel_regularizer=keras.regularizers.l1_l2(0,0.001))(y)\n",
        "  y = keras.layers.BatchNormalization()(y)\n",
        "  # if the shape of the shortcut and y aren't equal, we add a convolutional1D layer and a batch normalization to the shortcut\n",
        "  if input.shape[2] != y.shape[2]:\n",
        "    shortcut = keras.layers.Conv1D(filters = nFilters, kernel_size = kernelSize, strides = stride, padding = \"same\")(input)  \n",
        "    shortcut = keras.layers.BatchNormalization()(shortcut)\n",
        "  else:\n",
        "    shortcut = input\n",
        "  y = keras.layers.Add()([shortcut, y])\n",
        "  y = keras.layers.LeakyReLU()(y)\n",
        "  return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt8_B1Omo0wP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe55604-b817-4b3a-84f6-d00da111a89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 36750, 128)\n",
            "(None, 12250, 128)\n",
            "(None, 12250, 128)\n",
            "(None, 4083, 128)\n",
            "(None, 4083, 256)\n",
            "(None, 1361, 256)\n",
            "(None, 1361, 256)\n",
            "(None, 453, 256)\n",
            "(None, 453, 256)\n",
            "(None, 151, 256)\n",
            "(None, 151, 256)\n",
            "(None, 50, 256)\n",
            "(None, 50, 256)\n",
            "(None, 16, 256)\n",
            "(None, 16, 256)\n",
            "(None, 5, 256)\n",
            "(None, 5, 512)\n",
            "(None, 1, 512)\n"
          ]
        }
      ],
      "source": [
        "x = keras.Input(shape=(110250,1))\n",
        "\n",
        "#First Convolutional Layer:\n",
        "y = keras.layers.Conv1D(filters=filter[0][1], kernel_size = kernelS, strides = stride[0], padding = \"same\",kernel_regularizer=keras.regularizers.l1_l2(0,0.001))(x)\n",
        "\n",
        "#Series of Residual Layers and MaxPools:\n",
        "for filterType in filter:\n",
        "  for i in range(filterType[0]):\n",
        "    y = res1d(y, filterType[1], kernelS, stride[1])\n",
        "    print(y.shape)\n",
        "    y = keras.layers.MaxPooling1D(pool_size = poolS, strides = stride[0])(y)\n",
        "    print(y.shape)\n",
        "\n",
        "#Last convolutional layer\n",
        "y = keras.layers.Conv1D(filters=filter[2][1], kernel_size = 1, strides = stride[1], padding = \"same\")(y)\n",
        "\n",
        "#Last layers for output\n",
        "y = keras.layers.Flatten()(y)\n",
        "predictions = keras.layers.Dense(10, activation='softmax')(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = keras.Model(inputs=x, outputs=predictions)\n",
        "model = keras.models.load_model(\"/content/drive/MyDrive/TrainingRegularization/1Train2Valid/model.h5\")"
      ],
      "metadata": {
        "id": "TRZhriDPecVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling \n",
        "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer='adam', metrics=keras.metrics.sparse_categorical_accuracy)\n"
      ],
      "metadata": {
        "id": "egiREYA9gvne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOzRs2Rhh1Ed",
        "outputId": "67db7b3f-5f1e-416a-92f4-240a30161d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 110250, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)             (None, 36750, 128)   512         ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)             (None, 36750, 128)   49280       ['conv1d_22[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 36750, 128)  512         ['conv1d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 36750, 128)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_24 (Conv1D)             (None, 36750, 128)   49280       ['leaky_re_lu_18[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 36750, 128)  512         ['conv1d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 36750, 128)   0           ['conv1d_22[0][0]',              \n",
            "                                                                  'batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 36750, 128)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_9 (MaxPooling1D)  (None, 12250, 128)  0           ['leaky_re_lu_19[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 12250, 128)   49280       ['max_pooling1d_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 12250, 128)  512         ['conv1d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 12250, 128)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 12250, 128)   49280       ['leaky_re_lu_20[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 12250, 128)  512         ['conv1d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 12250, 128)   0           ['max_pooling1d_9[0][0]',        \n",
            "                                                                  'batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 12250, 128)   0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_10 (MaxPooling1D  (None, 4083, 128)   0           ['leaky_re_lu_21[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 4083, 256)    98560       ['max_pooling1d_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 4083, 256)   1024        ['conv1d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 4083, 256)    0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 4083, 256)    98560       ['max_pooling1d_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 4083, 256)    196864      ['leaky_re_lu_22[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 4083, 256)   1024        ['conv1d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 4083, 256)   1024        ['conv1d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 4083, 256)    0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_23 (LeakyReLU)     (None, 4083, 256)    0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_11 (MaxPooling1D  (None, 1361, 256)   0           ['leaky_re_lu_23[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 1361, 256)    196864      ['max_pooling1d_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 1361, 256)   1024        ['conv1d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_24 (LeakyReLU)     (None, 1361, 256)    0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 1361, 256)    196864      ['leaky_re_lu_24[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 1361, 256)   1024        ['conv1d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 1361, 256)    0           ['max_pooling1d_11[0][0]',       \n",
            "                                                                  'batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_25 (LeakyReLU)     (None, 1361, 256)    0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_12 (MaxPooling1D  (None, 453, 256)    0           ['leaky_re_lu_25[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 453, 256)     196864      ['max_pooling1d_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 453, 256)    1024        ['conv1d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_26 (LeakyReLU)     (None, 453, 256)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 453, 256)     196864      ['leaky_re_lu_26[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 453, 256)    1024        ['conv1d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 453, 256)     0           ['max_pooling1d_12[0][0]',       \n",
            "                                                                  'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_27 (LeakyReLU)     (None, 453, 256)     0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_13 (MaxPooling1D  (None, 151, 256)    0           ['leaky_re_lu_27[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_34 (Conv1D)             (None, 151, 256)     196864      ['max_pooling1d_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 151, 256)    1024        ['conv1d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_28 (LeakyReLU)     (None, 151, 256)     0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 151, 256)     196864      ['leaky_re_lu_28[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 151, 256)    1024        ['conv1d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 151, 256)     0           ['max_pooling1d_13[0][0]',       \n",
            "                                                                  'batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_29 (LeakyReLU)     (None, 151, 256)     0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_14 (MaxPooling1D  (None, 50, 256)     0           ['leaky_re_lu_29[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 50, 256)      196864      ['max_pooling1d_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 50, 256)     1024        ['conv1d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_30 (LeakyReLU)     (None, 50, 256)      0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 50, 256)      196864      ['leaky_re_lu_30[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 50, 256)     1024        ['conv1d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 50, 256)      0           ['max_pooling1d_14[0][0]',       \n",
            "                                                                  'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_31 (LeakyReLU)     (None, 50, 256)      0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_15 (MaxPooling1D  (None, 16, 256)     0           ['leaky_re_lu_31[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 16, 256)      196864      ['max_pooling1d_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 16, 256)     1024        ['conv1d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_32 (LeakyReLU)     (None, 16, 256)      0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 16, 256)      196864      ['leaky_re_lu_32[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 16, 256)     1024        ['conv1d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 16, 256)      0           ['max_pooling1d_15[0][0]',       \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_33 (LeakyReLU)     (None, 16, 256)      0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_16 (MaxPooling1D  (None, 5, 256)      0           ['leaky_re_lu_33[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 5, 512)       393728      ['max_pooling1d_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 512)      2048        ['conv1d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_34 (LeakyReLU)     (None, 5, 512)       0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 5, 512)       393728      ['max_pooling1d_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 5, 512)       786944      ['leaky_re_lu_34[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 512)      2048        ['conv1d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 512)      2048        ['conv1d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 512)       0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_35 (LeakyReLU)     (None, 5, 512)       0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_17 (MaxPooling1D  (None, 1, 512)      0           ['leaky_re_lu_35[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 1, 512)       262656      ['max_pooling1d_17[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 512)          0           ['conv1d_43[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           5130        ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,423,946\n",
            "Trainable params: 4,413,194\n",
            "Non-trainable params: 10,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience = 4)\n",
        "callbacks_list = [early_stop]"
      ],
      "metadata": {
        "id": "dCmVEVi3d73Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "n_batch = 32\n",
        "# Fitting \n",
        "model.fit(x_train, y_train,validation_data = (x_valid, y_valid), epochs=n_epochs, batch_size=n_batch, callbacks=callbacks_list )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Hk15A6gyRG",
        "outputId": "0fe60b70-52ad-4026-c1b2-1e814dab9472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 178s 1s/step - loss: 1.1265 - sparse_categorical_accuracy: 0.7705 - val_loss: 4.4065 - val_sparse_categorical_accuracy: 0.4109\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 157s 1s/step - loss: 0.6846 - sparse_categorical_accuracy: 0.8876 - val_loss: 3.6815 - val_sparse_categorical_accuracy: 0.4103\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 157s 1s/step - loss: 0.6239 - sparse_categorical_accuracy: 0.9044 - val_loss: 8.4073 - val_sparse_categorical_accuracy: 0.3318\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 157s 1s/step - loss: 0.6391 - sparse_categorical_accuracy: 0.9030 - val_loss: 4.8446 - val_sparse_categorical_accuracy: 0.3161\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 157s 1s/step - loss: 0.5963 - sparse_categorical_accuracy: 0.9221 - val_loss: 4.9254 - val_sparse_categorical_accuracy: 0.3131\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 157s 1s/step - loss: 0.5832 - sparse_categorical_accuracy: 0.9302 - val_loss: 7.4447 - val_sparse_categorical_accuracy: 0.3033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a8c1fead0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/TrainingRegularization/2Train3Valid/model.h5\")"
      ],
      "metadata": {
        "id": "E9T1c0v8nVQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b1fe62-4410-4632-b2fd-693eeb785b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test=loadBatch(5)"
      ],
      "metadata": {
        "id": "2bBwO1G-woy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(x_test)"
      ],
      "metadata": {
        "id": "EFwppcUy2xWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "accuracy_test = keras.metrics.SparseCategoricalAccuracy()(y_test,y_hat)\n",
        "print('Accuracy (test dataset):%1.2f%%'% (accuracy_test * 100))"
      ],
      "metadata": {
        "id": "oEd1qK9cwaDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aggregation of the segments in the songs\n",
        "song=list()\n",
        "for genre in range(10):\n",
        "  seg = y_hat[y_test==genre,:]\n",
        "  pos = 0\n",
        "  resto = len(seg)%21\n",
        "  for i in range(int(len(seg)/21)):\n",
        "    counts = np.mean(seg[pos*21:pos*21 + 21],axis=0)\n",
        "    pos += 1\n",
        "    song.append(counts)\n",
        "  if resto > 0:\n",
        "    counts = np.mean(seg[pos*21:],axis=0)\n",
        "    song.append(counts)\n",
        "\n",
        "\n",
        "songTrue=list()\n",
        "for genre in range(10):\n",
        "  seg = y_test[y_test==genre]\n",
        "  pos = 0\n",
        "  resto = len(seg)%21\n",
        "  for i in range(int(len(seg)/21)):\n",
        "    counts = np.bincount(seg[pos*21:pos*21 + 21])\n",
        "    pos += 1\n",
        "    songTrue.append(np.argmax(counts))\n",
        "  if resto > 0:\n",
        "    counts = np.bincount(seg[pos*21:])\n",
        "    songTrue.append(np.argmax(counts))"
      ],
      "metadata": {
        "id": "O5P69nc7L6nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Aggregate\n",
        "accuracy_test = keras.metrics.SparseCategoricalAccuracy()(songTrue,song)\n",
        "print('Accuracy (test dataset):%1.2f%%'% (accuracy_test * 100))"
      ],
      "metadata": {
        "id": "_-MG6_TeHEtd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RegularizationModelNAML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}